\hypertarget{class_softmax}{}\doxysection{Класс Softmax}
\label{class_softmax}\index{Softmax@{Softmax}}


{\ttfamily \#include $<$Softmax.\+h$>$}

\doxysubsection*{Открытые статические члены}
\begin{DoxyCompactItemize}
\item 
static void \mbox{\hyperlink{class_softmax_a54bfad1c882349d8084c2a3968f75f74}{activate}} (const Matrix \&Z, Matrix \&A)
\item 
static void \mbox{\hyperlink{class_softmax_a9a2f8ae3aff1cc2ddced99e06c23efa9}{apply\+\_\+jacobian}} (const Matrix \&Z, const Matrix \&A, const Matrix \&F, Matrix \&G)
\begin{DoxyCompactList}\small\item\em Операция матричного дифференцирования. \end{DoxyCompactList}\item 
static std\+::string \mbox{\hyperlink{class_softmax_aa5a738d883c302282ee72d8e67080316}{return\+\_\+type}} ()
\end{DoxyCompactItemize}


\doxysubsection{Подробное описание}
Класс функции активации -\/ \mbox{\hyperlink{class_softmax}{Softmax}}. 

\doxysubsection{Методы}
\mbox{\Hypertarget{class_softmax_a54bfad1c882349d8084c2a3968f75f74}\label{class_softmax_a54bfad1c882349d8084c2a3968f75f74}} 
\index{Softmax@{Softmax}!activate@{activate}}
\index{activate@{activate}!Softmax@{Softmax}}
\doxysubsubsection{\texorpdfstring{activate()}{activate()}}
{\footnotesize\ttfamily static void Softmax\+::activate (\begin{DoxyParamCaption}\item[{const Matrix \&}]{Z,  }\item[{Matrix \&}]{A }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [static]}}

{\bfseries{Алгоритм}}\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int} softmax\_forward(\textcolor{keyword}{const} Matrix\& Z, Matrix\& A)\{}
\DoxyCodeLine{}
\DoxyCodeLine{    \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i < Z.size(); i++)}
\DoxyCodeLine{    \{}
\DoxyCodeLine{        A[i] = Z[i] * ( 1 / exp(Z).sum() );}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{\}}

\end{DoxyCode}
 
\begin{DoxyParams}{Аргументы}
{\em Z} & значения нейронов до активации \\
\hline
{\em A} & значения нейронов после активации \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{class_softmax_a9a2f8ae3aff1cc2ddced99e06c23efa9}\label{class_softmax_a9a2f8ae3aff1cc2ddced99e06c23efa9}} 
\index{Softmax@{Softmax}!apply\_jacobian@{apply\_jacobian}}
\index{apply\_jacobian@{apply\_jacobian}!Softmax@{Softmax}}
\doxysubsubsection{\texorpdfstring{apply\_jacobian()}{apply\_jacobian()}}
{\footnotesize\ttfamily static void Softmax\+::apply\+\_\+jacobian (\begin{DoxyParamCaption}\item[{const Matrix \&}]{Z,  }\item[{const Matrix \&}]{A,  }\item[{const Matrix \&}]{F,  }\item[{Matrix \&}]{G }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [static]}}



Операция матричного дифференцирования. 

{\bfseries{Алгоритм}}\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int} softmax\_backprop(\textcolor{keyword}{const} Matrix\& Z, \textcolor{keyword}{const} Matrix\& A,}
\DoxyCodeLine{    \textcolor{keyword}{const} Matrix\& F, Matrix\& G) \{}
\DoxyCodeLine{}
\DoxyCodeLine{    \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i < A.size(); i++)}
\DoxyCodeLine{    \{}
\DoxyCodeLine{        G = A * (F -\/ transpose(A));}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{\}}

\end{DoxyCode}
 
\begin{DoxyParams}{Аргументы}
{\em Z} & нейроны слоя до активации. \\
\hline
{\em A} & нейроны слоя после активации. \\
\hline
{\em F} & нейроны следующего слоя. \\
\hline
{\em G} & значения, которые получаются после backprop. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{class_softmax_aa5a738d883c302282ee72d8e67080316}\label{class_softmax_aa5a738d883c302282ee72d8e67080316}} 
\index{Softmax@{Softmax}!return\_type@{return\_type}}
\index{return\_type@{return\_type}!Softmax@{Softmax}}
\doxysubsubsection{\texorpdfstring{return\_type()}{return\_type()}}
{\footnotesize\ttfamily static std\+::string Softmax\+::return\+\_\+type (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [static]}}

\begin{DoxyReturn}{Возвращает}
Тип активации. 
\end{DoxyReturn}


Объявления и описания членов класса находятся в файле\+:\begin{DoxyCompactItemize}
\item 
/home/shuffle/xs\+DNN/xs\+DNN-\/include/neuralnetwork/\+Activation/Softmax.\+h\end{DoxyCompactItemize}
