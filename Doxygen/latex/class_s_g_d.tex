\hypertarget{class_s_g_d}{}\doxysection{Класс SGD}
\label{class_s_g_d}\index{SGD@{SGD}}


{\ttfamily \#include $<$SGD.\+h$>$}



Граф наследования\+:SGD\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=145pt]{class_s_g_d__inherit__graph}
\end{center}
\end{figure}


Граф связей класса SGD\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=145pt]{class_s_g_d__coll__graph}
\end{center}
\end{figure}
\doxysubsection*{Открытые члены}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_s_g_d_ac78d296e8a5afdecf22fa62e34d99f2d}{SGD}} (const Scalar \&lrate=Scalar(0.\+01), const Scalar \&decay=Scalar(0))
\item 
void \mbox{\hyperlink{class_s_g_d_a0f825311969e0031e0b78c804df61e21}{update}} (Const\+Aligned\+Map\+Vec \&dvec, Aligned\+Map\+Vec \&vec)
\end{DoxyCompactItemize}
\doxysubsection*{Открытые атрибуты}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_s_g_d_a022ad12dff64d757823467dda852c541}\label{class_s_g_d_a022ad12dff64d757823467dda852c541}} 
Scalar \mbox{\hyperlink{class_s_g_d_a022ad12dff64d757823467dda852c541}{m\+\_\+lrate}}
\begin{DoxyCompactList}\small\item\em длина шага. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{class_s_g_d_a48ff7e4475ca615151ee0b5db8714c57}\label{class_s_g_d_a48ff7e4475ca615151ee0b5db8714c57}} 
Scalar \mbox{\hyperlink{class_s_g_d_a48ff7e4475ca615151ee0b5db8714c57}{m\+\_\+decay}}
\begin{DoxyCompactList}\small\item\em коэффицент линейной зависимости с производной. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Подробное описание}
Класс управления стохастическим градиентным спуском. 

\doxysubsection{Конструктор(ы)}
\mbox{\Hypertarget{class_s_g_d_ac78d296e8a5afdecf22fa62e34d99f2d}\label{class_s_g_d_ac78d296e8a5afdecf22fa62e34d99f2d}} 
\index{SGD@{SGD}!SGD@{SGD}}
\index{SGD@{SGD}!SGD@{SGD}}
\doxysubsubsection{\texorpdfstring{SGD()}{SGD()}}
{\footnotesize\ttfamily SGD\+::\+SGD (\begin{DoxyParamCaption}\item[{const Scalar \&}]{lrate = {\ttfamily Scalar(0.01)},  }\item[{const Scalar \&}]{decay = {\ttfamily Scalar(0)} }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}


\begin{DoxyParams}{Аргументы}
{\em lrate} & длина шага. \\
\hline
{\em decay} & коэффицент линейной зависимости с производной. \\
\hline
\end{DoxyParams}


\doxysubsection{Методы}
\mbox{\Hypertarget{class_s_g_d_a0f825311969e0031e0b78c804df61e21}\label{class_s_g_d_a0f825311969e0031e0b78c804df61e21}} 
\index{SGD@{SGD}!update@{update}}
\index{update@{update}!SGD@{SGD}}
\doxysubsubsection{\texorpdfstring{update()}{update()}}
{\footnotesize\ttfamily void SGD\+::update (\begin{DoxyParamCaption}\item[{Const\+Aligned\+Map\+Vec \&}]{dvec,  }\item[{Aligned\+Map\+Vec \&}]{vec }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

Обновление весов слоя по формуле -\/$>$

w\+\_\+0 -\/= m\+\_\+lrate $\ast$ (dvec + m\+\_\+decay $\ast$ vec); 
\begin{DoxyParams}{Аргументы}
{\em dvec} & вектор производной (например веса или смещения) \\
\hline
{\em vec} & вектор значений (например веса или смещения) \\
\hline
\end{DoxyParams}


Объявления и описания членов класса находятся в файле\+:\begin{DoxyCompactItemize}
\item 
/home/shuffle/xs\+DNN/xs\+DNN-\/include/neuralnetwork/\+Optimizer/SGD.\+h\end{DoxyCompactItemize}
